Time difference of 19.78488 mins
[1] "==============="
Regularized Discriminant Analysis 

800 samples
 40 predictor
  2 classes: '0', '1' 

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 2 times) 

Summary of sample sizes: 720, 720, 720, 719, 720, 719, ... 

Resampling results across tuning parameters:

  gamma   lambda  Accuracy  Kappa  Accuracy SD  Kappa SD
  0.0000  0.0000    NaN       NaN      NA           NA  
  0.0000  0.0909    NaN       NaN      NA           NA  
  0.0000  0.1818    NaN       NaN      NA           NA  
  0.0000  0.2727    NaN       NaN      NA           NA  
  0.0000  0.3636    NaN       NaN      NA           NA  
  0.0000  0.4545    NaN       NaN      NA           NA  
  0.0000  0.5455    NaN       NaN      NA           NA  
  0.0000  0.6364    NaN       NaN      NA           NA  
  0.0000  0.7273    NaN       NaN      NA           NA  
  0.0000  0.8182    NaN       NaN      NA           NA  
  0.0000  0.9091    NaN       NaN      NA           NA  
  0.0000  1.0000    NaN       NaN      NA           NA  
  0.0909  0.0000  0.886     0.771  0.0412       0.0823  
  0.0909  0.0909  0.883     0.766  0.0398       0.0795  
  0.0909  0.1818  0.888     0.776  0.0400       0.0800  
  0.0909  0.2727  0.887     0.774  0.0405       0.0809  
  0.0909  0.3636  0.886     0.771  0.0401       0.0801  
  0.0909  0.4545  0.885     0.770  0.0393       0.0786  
  0.0909  0.5455  0.888     0.775  0.0393       0.0784  
  0.0909  0.6364  0.886     0.771  0.0433       0.0864  
  0.0909  0.7273  0.886     0.773  0.0414       0.0828  
  0.0909  0.8182  0.887     0.774  0.0410       0.0818  
  0.0909  0.9091  0.885     0.770  0.0414       0.0828  
  0.0909  1.0000  0.886     0.771  0.0406       0.0811  
  0.1818  0.0000  0.881     0.761  0.0428       0.0855  
  0.1818  0.0909  0.885     0.770  0.0400       0.0799  
  0.1818  0.1818  0.881     0.763  0.0424       0.0847  
  0.1818  0.2727  0.884     0.768  0.0416       0.0831  
  0.1818  0.3636  0.883     0.765  0.0440       0.0879  
  0.1818  0.4545  0.881     0.763  0.0408       0.0814  
  0.1818  0.5455  0.886     0.773  0.0396       0.0792  
  0.1818  0.6364  0.881     0.763  0.0417       0.0835  
  0.1818  0.7273  0.882     0.764  0.0425       0.0850  
  0.1818  0.8182  0.881     0.763  0.0430       0.0859  
  0.1818  0.9091  0.884     0.768  0.0375       0.0750  
  0.1818  1.0000  0.883     0.766  0.0412       0.0825  
  0.2727  0.0000  0.881     0.761  0.0444       0.0886  
  0.2727  0.0909  0.880     0.760  0.0456       0.0910  
  0.2727  0.1818  0.880     0.760  0.0446       0.0889  
  0.2727  0.2727  0.878     0.755  0.0452       0.0904  
  0.2727  0.3636  0.879     0.758  0.0456       0.0911  
  0.2727  0.4545  0.880     0.759  0.0430       0.0858  
  0.2727  0.5455  0.878     0.755  0.0440       0.0879  
  0.2727  0.6364  0.879     0.758  0.0433       0.0866  
  0.2727  0.7273  0.878     0.757  0.0429       0.0856  
  0.2727  0.8182  0.880     0.760  0.0433       0.0865  
  0.2727  0.9091  0.879     0.758  0.0450       0.0899  
  0.2727  1.0000  0.879     0.758  0.0418       0.0835  
  0.3636  0.0000  0.873     0.745  0.0450       0.0899  
  0.3636  0.0909  0.874     0.748  0.0418       0.0834  
  0.3636  0.1818  0.875     0.749  0.0428       0.0854  
  0.3636  0.2727  0.876     0.752  0.0436       0.0871  
  0.3636  0.3636  0.875     0.750  0.0455       0.0908  
  0.3636  0.4545  0.875     0.749  0.0441       0.0881  
  0.3636  0.5455  0.873     0.747  0.0451       0.0901  
  0.3636  0.6364  0.873     0.745  0.0434       0.0866  
  0.3636  0.7273  0.876     0.753  0.0431       0.0859  
  0.3636  0.8182  0.872     0.744  0.0451       0.0899  
  0.3636  0.9091  0.873     0.747  0.0466       0.0930  
  0.3636  1.0000  0.876     0.752  0.0432       0.0862  
  0.4545  0.0000  0.871     0.742  0.0447       0.0892  
  0.4545  0.0909  0.871     0.742  0.0439       0.0877  
  0.4545  0.1818  0.870     0.740  0.0440       0.0879  
  0.4545  0.2727  0.869     0.738  0.0442       0.0882  
  0.4545  0.3636  0.871     0.743  0.0437       0.0873  
  0.4545  0.4545  0.868     0.735  0.0440       0.0877  
  0.4545  0.5455  0.871     0.742  0.0439       0.0877  
  0.4545  0.6364  0.868     0.737  0.0469       0.0935  
  0.4545  0.7273  0.871     0.743  0.0441       0.0881  
  0.4545  0.8182  0.869     0.738  0.0436       0.0870  
  0.4545  0.9091  0.870     0.740  0.0436       0.0870  
  0.4545  1.0000  0.869     0.738  0.0467       0.0932  
  0.5455  0.0000  0.866     0.732  0.0422       0.0842  
  0.5455  0.0909  0.868     0.737  0.0421       0.0839  
  0.5455  0.1818  0.870     0.740  0.0403       0.0804  
  0.5455  0.2727  0.868     0.736  0.0408       0.0814  
  0.5455  0.3636  0.868     0.736  0.0391       0.0779  
  0.5455  0.4545  0.867     0.734  0.0405       0.0809  
  0.5455  0.5455  0.870     0.740  0.0401       0.0799  
  0.5455  0.6364  0.871     0.741  0.0401       0.0799  
  0.5455  0.7273  0.871     0.742  0.0408       0.0814  
  0.5455  0.8182  0.865     0.730  0.0382       0.0763  
  0.5455  0.9091  0.862     0.724  0.0378       0.0754  
  0.5455  1.0000  0.867     0.734  0.0425       0.0849  
  0.6364  0.0000  0.864     0.729  0.0412       0.0821  
  0.6364  0.0909  0.863     0.725  0.0372       0.0742  
  0.6364  0.1818  0.865     0.730  0.0402       0.0803  
  0.6364  0.2727  0.864     0.728  0.0387       0.0772  
  0.6364  0.3636  0.864     0.728  0.0383       0.0763  
  0.6364  0.4545  0.864     0.728  0.0402       0.0801  
  0.6364  0.5455  0.865     0.730  0.0372       0.0740  
  0.6364  0.6364  0.864     0.728  0.0394       0.0784  
  0.6364  0.7273  0.864     0.729  0.0398       0.0793  
  0.6364  0.8182  0.863     0.726  0.0376       0.0749  
  0.6364  0.9091  0.863     0.726  0.0386       0.0770  
  0.6364  1.0000  0.864     0.728  0.0377       0.0751  
  0.7273  0.0000  0.859     0.718  0.0359       0.0716  
  0.7273  0.0909  0.858     0.716  0.0355       0.0709  
  0.7273  0.1818  0.860     0.720  0.0342       0.0682  
  0.7273  0.2727  0.860     0.719  0.0367       0.0733  
  0.7273  0.3636  0.861     0.721  0.0360       0.0718  
  0.7273  0.4545  0.861     0.723  0.0359       0.0716  
  0.7273  0.5455  0.859     0.719  0.0361       0.0721  
  0.7273  0.6364  0.859     0.719  0.0355       0.0708  
  0.7273  0.7273  0.861     0.721  0.0355       0.0709  
  0.7273  0.8182  0.861     0.721  0.0360       0.0718  
  0.7273  0.9091  0.859     0.719  0.0367       0.0733  
  0.7273  1.0000  0.861     0.723  0.0359       0.0716  
  0.8182  0.0000  0.849     0.698  0.0375       0.0749  
  0.8182  0.0909  0.848     0.696  0.0363       0.0724  
  0.8182  0.1818  0.848     0.695  0.0370       0.0738  
  0.8182  0.2727  0.848     0.696  0.0377       0.0752  
  0.8182  0.3636  0.848     0.696  0.0361       0.0721  
  0.8182  0.4545  0.848     0.695  0.0359       0.0717  
  0.8182  0.5455  0.848     0.695  0.0368       0.0734  
  0.8182  0.6364  0.848     0.696  0.0372       0.0742  
  0.8182  0.7273  0.849     0.698  0.0364       0.0727  
  0.8182  0.8182  0.848     0.695  0.0359       0.0717  
  0.8182  0.9091  0.848     0.696  0.0361       0.0721  
  0.8182  1.0000  0.849     0.698  0.0364       0.0727  
  0.9091  0.0000  0.831     0.661  0.0398       0.0796  
  0.9091  0.0909  0.830     0.660  0.0392       0.0784  
  0.9091  0.1818  0.831     0.661  0.0398       0.0796  
  0.9091  0.2727  0.831     0.661  0.0398       0.0796  
  0.9091  0.3636  0.829     0.659  0.0384       0.0767  
  0.9091  0.4545  0.830     0.660  0.0392       0.0784  
  0.9091  0.5455  0.830     0.660  0.0392       0.0784  
  0.9091  0.6364  0.831     0.661  0.0398       0.0796  
  0.9091  0.7273  0.830     0.660  0.0392       0.0784  
  0.9091  0.8182  0.830     0.660  0.0392       0.0784  
  0.9091  0.9091  0.831     0.661  0.0398       0.0796  
  0.9091  1.0000  0.830     0.660  0.0392       0.0784  
  1.0000  0.0000  0.803     0.605  0.0376       0.0750  
  1.0000  0.0909  0.805     0.610  0.0386       0.0770  
  1.0000  0.1818  0.806     0.613  0.0388       0.0775  
  1.0000  0.2727  0.803     0.605  0.0397       0.0793  
  1.0000  0.3636  0.803     0.605  0.0401       0.0800  
  1.0000  0.4545  0.803     0.605  0.0384       0.0767  
  1.0000  0.5455  0.804     0.608  0.0383       0.0764  
  1.0000  0.6364  0.804     0.608  0.0395       0.0789  
  1.0000  0.7273  0.805     0.610  0.0400       0.0798  
  1.0000  0.8182  0.802     0.604  0.0396       0.0790  
  1.0000  0.9091  0.804     0.608  0.0404       0.0806  
  1.0000  1.0000  0.803     0.605  0.0389       0.0776  

Kappa was used to select the optimal model using  the largest value.
The final values used for the model were gamma = 0.09090909 and lambda = 0.1818182. 
[1] "==============="
Confusion Matrix and Statistics

          Reference
Prediction  0  1
         0 91  6
         1  7 96
                                          
               Accuracy : 0.935           
                 95% CI : (0.8914, 0.9649)
    No Information Rate : 0.51            
    P-Value [Acc > NIR] : <2e-16          
                                          
                  Kappa : 0.8699          
 Mcnemar's Test P-Value : 1               
                                          
            Sensitivity : 0.9286          
            Specificity : 0.9412          
         Pos Pred Value : 0.9381          
         Neg Pred Value : 0.9320          
             Prevalence : 0.4900          
         Detection Rate : 0.4550          
   Detection Prevalence : 0.4850          
      Balanced Accuracy : 0.9349          
                                          
       'Positive' Class : 0               
                                          
