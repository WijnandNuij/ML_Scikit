Time difference of 22.19623 mins
[1] "==============="
Random Forest by Randomization 

800 samples
 40 predictor
  2 classes: '0', '1' 

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 2 times) 

Summary of sample sizes: 721, 720, 720, 720, 720, 719, ... 

Resampling results across tuning parameters:

  mtry  numRandomCuts  Accuracy  Kappa  Accuracy SD  Kappa SD
   2     1             0.857     0.714  0.0380       0.0760  
   2     2             0.859     0.719  0.0399       0.0796  
   2     3             0.864     0.729  0.0359       0.0715  
   2     4             0.866     0.731  0.0354       0.0706  
   2     5             0.861     0.721  0.0400       0.0798  
   2     6             0.861     0.722  0.0373       0.0744  
   2     7             0.864     0.727  0.0370       0.0737  
   2     8             0.868     0.736  0.0356       0.0710  
   2     9             0.866     0.732  0.0354       0.0705  
   2    10             0.859     0.719  0.0382       0.0761  
   2    11             0.859     0.719  0.0363       0.0724  
   2    12             0.862     0.724  0.0372       0.0741  
   5     1             0.874     0.749  0.0393       0.0785  
   5     2             0.874     0.749  0.0383       0.0764  
   5     3             0.876     0.753  0.0362       0.0722  
   5     4             0.882     0.764  0.0350       0.0698  
   5     5             0.879     0.758  0.0407       0.0813  
   5     6             0.877     0.754  0.0370       0.0737  
   5     7             0.879     0.758  0.0387       0.0771  
   5     8             0.881     0.763  0.0383       0.0763  
   5     9             0.878     0.756  0.0355       0.0708  
   5    10             0.879     0.758  0.0361       0.0718  
   5    11             0.883     0.766  0.0380       0.0758  
   5    12             0.879     0.758  0.0311       0.0619  
   8     1             0.871     0.741  0.0372       0.0743  
   8     2             0.883     0.765  0.0377       0.0752  
   8     3             0.883     0.765  0.0361       0.0719  
   8     4             0.883     0.765  0.0349       0.0697  
   8     5             0.886     0.771  0.0345       0.0687  
   8     6             0.886     0.773  0.0343       0.0684  
   8     7             0.888     0.775  0.0401       0.0800  
   8     8             0.884     0.769  0.0422       0.0843  
   8     9             0.887     0.774  0.0404       0.0806  
   8    10             0.886     0.773  0.0393       0.0784  
   8    11             0.885     0.770  0.0388       0.0774  
   8    12             0.887     0.774  0.0405       0.0808  
  12     1             0.882     0.764  0.0391       0.0781  
  12     2             0.884     0.769  0.0376       0.0750  
  12     3             0.886     0.773  0.0394       0.0787  
  12     4             0.889     0.779  0.0334       0.0667  
  12     5             0.886     0.771  0.0385       0.0768  
  12     6             0.891     0.783  0.0397       0.0793  
  12     7             0.888     0.775  0.0425       0.0848  
  12     8             0.893     0.786  0.0365       0.0729  
  12     9             0.889     0.779  0.0388       0.0776  
  12    10             0.890     0.780  0.0430       0.0858  
  12    11             0.890     0.780  0.0370       0.0739  
  12    12             0.893     0.786  0.0418       0.0835  
  15     1             0.885     0.770  0.0368       0.0735  
  15     2             0.887     0.774  0.0337       0.0673  
  15     3             0.889     0.779  0.0405       0.0810  
  15     4             0.888     0.775  0.0382       0.0762  
  15     5             0.889     0.778  0.0355       0.0708  
  15     6             0.888     0.776  0.0420       0.0839  
  15     7             0.894     0.789  0.0418       0.0834  
  15     8             0.893     0.786  0.0381       0.0760  
  15     9             0.892     0.784  0.0410       0.0818  
  15    10             0.888     0.775  0.0355       0.0708  
  15    11             0.892     0.784  0.0358       0.0715  
  15    12             0.891     0.781  0.0375       0.0749  
  19     1             0.884     0.769  0.0407       0.0813  
  19     2             0.885     0.770  0.0359       0.0717  
  19     3             0.887     0.774  0.0422       0.0842  
  19     4             0.888     0.776  0.0424       0.0847  
  19     5             0.893     0.786  0.0379       0.0757  
  19     6             0.889     0.778  0.0383       0.0765  
  19     7             0.890     0.780  0.0392       0.0782  
  19     8             0.888     0.776  0.0376       0.0752  
  19     9             0.888     0.776  0.0376       0.0751  
  19    10             0.887     0.774  0.0365       0.0729  
  19    11             0.889     0.779  0.0344       0.0687  
  19    12             0.885     0.770  0.0404       0.0807  
  22     1             0.886     0.771  0.0382       0.0764  
  22     2             0.888     0.776  0.0391       0.0782  
  22     3             0.888     0.775  0.0380       0.0758  
  22     4             0.890     0.780  0.0381       0.0761  
  22     5             0.897     0.794  0.0381       0.0761  
  22     6             0.887     0.774  0.0382       0.0764  
  22     7             0.887     0.774  0.0395       0.0789  
  22     8             0.890     0.780  0.0317       0.0632  
  22     9             0.891     0.783  0.0358       0.0715  
  22    10             0.890     0.780  0.0387       0.0774  
  22    11             0.883     0.766  0.0383       0.0766  
  22    12             0.890     0.780  0.0376       0.0752  
  26     1             0.884     0.769  0.0403       0.0804  
  26     2             0.888     0.775  0.0369       0.0737  
  26     3             0.886     0.773  0.0368       0.0735  
  26     4             0.890     0.780  0.0368       0.0735  
  26     5             0.890     0.780  0.0384       0.0766  
  26     6             0.888     0.775  0.0386       0.0771  
  26     7             0.888     0.776  0.0347       0.0693  
  26     8             0.884     0.769  0.0323       0.0646  
  26     9             0.885     0.770  0.0324       0.0647  
  26    10             0.888     0.775  0.0336       0.0671  
  26    11             0.887     0.774  0.0349       0.0696  
  26    12             0.886     0.771  0.0354       0.0707  
  29     1             0.887     0.774  0.0381       0.0760  
  29     2             0.891     0.783  0.0369       0.0737  
  29     3             0.891     0.783  0.0380       0.0759  
  29     4             0.889     0.779  0.0351       0.0702  
  29     5             0.887     0.774  0.0351       0.0701  
  29     6             0.890     0.780  0.0325       0.0650  
  29     7             0.883     0.766  0.0349       0.0696  
  29     8             0.886     0.773  0.0348       0.0695  
  29     9             0.883     0.766  0.0348       0.0696  
  29    10             0.883     0.765  0.0379       0.0758  
  29    11             0.881     0.763  0.0368       0.0735  
  29    12             0.879     0.759  0.0364       0.0727  
  33     1             0.888     0.776  0.0400       0.0799  
  33     2             0.892     0.784  0.0334       0.0666  
  33     3             0.887     0.774  0.0346       0.0691  
  33     4             0.885     0.770  0.0350       0.0699  
  33     5             0.889     0.778  0.0333       0.0665  
  33     6             0.884     0.768  0.0329       0.0657  
  33     7             0.884     0.769  0.0335       0.0669  
  33     8             0.886     0.773  0.0315       0.0629  
  33     9             0.884     0.769  0.0343       0.0686  
  33    10             0.881     0.763  0.0333       0.0667  
  33    11             0.876     0.751  0.0329       0.0658  
  33    12             0.878     0.755  0.0349       0.0697  
  36     1             0.887     0.774  0.0347       0.0693  
  36     2             0.886     0.771  0.0319       0.0637  
  36     3             0.887     0.774  0.0352       0.0702  
  36     4             0.892     0.784  0.0349       0.0696  
  36     5             0.883     0.766  0.0348       0.0695  
  36     6             0.884     0.769  0.0315       0.0629  
  36     7             0.884     0.768  0.0328       0.0655  
  36     8             0.881     0.763  0.0329       0.0659  
  36     9             0.880     0.760  0.0373       0.0745  
  36    10             0.876     0.753  0.0325       0.0650  
  36    11             0.879     0.758  0.0323       0.0645  
  36    12             0.875     0.750  0.0343       0.0684  
  40     1             0.886     0.771  0.0374       0.0746  
  40     2             0.886     0.771  0.0374       0.0746  
  40     3             0.886     0.771  0.0367       0.0733  
  40     4             0.886     0.771  0.0329       0.0657  
  40     5             0.883     0.766  0.0362       0.0723  
  40     6             0.881     0.763  0.0314       0.0626  
  40     7             0.877     0.754  0.0333       0.0666  
  40     8             0.879     0.758  0.0349       0.0698  
  40     9             0.876     0.751  0.0329       0.0658  
  40    10             0.876     0.753  0.0310       0.0618  
  40    11             0.872     0.744  0.0333       0.0665  
  40    12             0.872     0.744  0.0327       0.0654  

Kappa was used to select the optimal model using  the largest value.
The final values used for the model were mtry = 22 and numRandomCuts = 5. 
[1] "==============="
Confusion Matrix and Statistics

          Reference
Prediction  0  1
         0 86 13
         1 12 89
                                         
               Accuracy : 0.875          
                 95% CI : (0.821, 0.9174)
    No Information Rate : 0.51           
    P-Value [Acc > NIR] : <2e-16         
                                         
                  Kappa : 0.7499         
 Mcnemar's Test P-Value : 1              
                                         
            Sensitivity : 0.8776         
            Specificity : 0.8725         
         Pos Pred Value : 0.8687         
         Neg Pred Value : 0.8812         
             Prevalence : 0.4900         
         Detection Rate : 0.4300         
   Detection Prevalence : 0.4950         
      Balanced Accuracy : 0.8751         
                                         
       'Positive' Class : 0              
                                         
